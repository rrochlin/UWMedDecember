{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "5751d7c496c272386542b26abd80dd065779a39feb74bf22f2b4e5e7f629ef29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### General Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import glob\n",
    "from cleanUp import cleanUp\n",
    "from fillDf import fillDf\n",
    "from fixYearStamp import fixYearStamp\n",
    "from sklearn.cluster import KMeans\n",
    "import time as clock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = clock.time()"
   ]
  },
  {
   "source": [
    "### Data Cleaning\n",
    "Passing the sensor data through the cleanUp function to get fix timestamps and delete null timestamps."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_files = glob.glob(\"./Data/*.txt\")\n",
    "# insert the desired start time\n",
    "cutOffTime = '12/22/2020 12:49:00'\n",
    "endTime = '12/22/2020 16:10:00'\n",
    "# insert the time rectifying offsets. default of for nothing {'':0}\n",
    "sensorConditions = {'S-01':1,'S-02':1,'S-03':1,'S-04':1,'S-05':1,'S-06':1,'S-07':1,'S-08':1,'S-09':1,'S-10':1,'S-11':1,'S-12':1,'S-13':1,'S-14':1,'S-15':1,'S-BU1':8,'S-BU2':8}\n",
    "#This indicates which columns to keep. Here we're taking all of the dP info and the timestamps\n",
    "columns = [0,1,6,7,8,9,10,11]\n",
    "# Enable Data Checking\n",
    "DataChecking = True\n",
    "# Here are obversed timestamps that need to removed from the data\n",
    "badTimes = ['     0/0/0      0:0:0','2165/165/165 165:165:85']\n",
    "# Controls wether zones will be created automatically or by k-means clusters\n",
    "ZoneAutomation = False\n",
    "# Sets either the binning or the manual zones\n",
    "numberOfZones = 4\n",
    "numAutoZones = 3\n",
    "# Sensors to exclude from zone\n",
    "outdoorSensors = ['S-16','S-17','S-18','S-19']\n",
    "# 10s of seconds before nebulization to include in the expirement csv files\n",
    "preCursorFactor = 6\n",
    "# which particle to analyze\n",
    "particle = 'Dp>0.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "expTRange = {\n",
    "    'OR7 Unblocked':\n",
    "    [pd.Timestamp('12-22-2020 13:08:00')-pd.Timedelta(10,'S'),\n",
    "    pd.Timestamp('12-22-2020 13:16:30'),\n",
    "    pd.Timestamp('12-22-2020 13:34:15')-pd.Timedelta(10,'S')],\n",
    "    'OR7 Blocked':\n",
    "    [pd.Timestamp('12-22-2020 13:44:30')-pd.Timedelta(20,'S'),\n",
    "    pd.Timestamp('12-22-2020 13:53:00')-pd.Timedelta(20,'S'),\n",
    "    pd.Timestamp('12-22-2020 13:59:00')-pd.Timedelta(10,'S')],\n",
    "    'OR16 Unblocked':\n",
    "    [pd.Timestamp('12-22-2020 14:38:00'),\n",
    "    pd.Timestamp('12-22-2020 14:44:00')-pd.Timedelta(10,'S'),\n",
    "    pd.Timestamp('12-22-2020 14:50:00')-pd.Timedelta(10,'S')],\n",
    "    'OR16 Blocked 1':\n",
    "    [pd.Timestamp('12-22-2020 14:58:30')-pd.Timedelta(10,'S'),\n",
    "    pd.Timestamp('12-22-2020 15:05:15'),\n",
    "    pd.Timestamp('12-22-2020 15:11:00')],\n",
    "    'OR16 Blocked 2':\n",
    "    [pd.Timestamp('12-22-2020 15:17:30'),\n",
    "    pd.Timestamp('12-22-2020 15:23:00'),\n",
    "    pd.Timestamp('12-22-2020 15:30:00')],\n",
    "}\n",
    "\n",
    "#enter in the expirement length as seconds/10\n",
    "expTLen = {\n",
    "    'OR7 Unblocked' :   5*6,\n",
    "    'OR7 Blocked':      5*6,\n",
    "    'OR16 Unblocked':   5*6,\n",
    "    'OR16 Blocked 1':   5*6,\n",
    "    'OR16 Blocked 2':   5*6\n",
    "}\n",
    "\n",
    "# Manual Zone set up notice how we are missing S-14\n",
    "zoneList = {\n",
    "    'Zone 1' : ['S-13','S-14'],\n",
    "    'Zone 2' : ['S-09','S-11','S-12'],\n",
    "    'Zone 3' : ['S-01','S-03','S-04','S-05','S-06','S-07','S-08','S-15'],\n",
    "    'Zone 4' : ['S-BU1']\n",
    "}\n",
    "if not ZoneAutomation:\n",
    "    numberOfZones = len(zoneList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['./Data\\\\S-01.txt',\n",
       " './Data\\\\S-03.txt',\n",
       " './Data\\\\S-04.txt',\n",
       " './Data\\\\S-05.txt',\n",
       " './Data\\\\S-06.txt',\n",
       " './Data\\\\S-07.txt',\n",
       " './Data\\\\S-08.txt',\n",
       " './Data\\\\S-09.txt',\n",
       " './Data\\\\S-11.txt',\n",
       " './Data\\\\S-12.txt',\n",
       " './Data\\\\S-13.txt',\n",
       " './Data\\\\S-14.txt',\n",
       " './Data\\\\S-15.txt',\n",
       " './Data\\\\S-BU1.txt']"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "all_csv_files"
   ]
  },
  {
   "source": [
    "Changed this to markdown so it won't run twice, had to fix the timestamps on S-12\n",
    "filePath        = all_csv_files[11]\n",
    "incorrectString = '21/3/22'\n",
    "date            = '3/22/2021'\n",
    "charTimeStart   = 11\n",
    "charTimeEnd     = 21\n",
    "offset          = 0\n",
    "fixYearStamp(filePath,incorrectString,date,charTimeStart,charTimeEnd,offset)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S-01     2020-12-22 12:49:10      2020-12-22 16:09:31       mod: yes\nS-03     2020-12-22 12:49:03      2020-12-22 16:09:35       mod: yes\nS-04     2020-12-22 12:49:07      2020-12-22 16:09:34       mod: yes\nS-05     2020-12-22 12:49:01      2020-12-22 16:10:50       mod: yes\nS-06     2020-12-22 12:49:12      2020-12-22 16:09:25       mod: yes\nS-07     2020-12-22 12:49:07      2020-12-22 16:12:53       mod: yes\nS-08     2020-12-22 12:49:24      2020-12-22 16:57:24       mod: yes\nS-09     2020-12-22 12:49:00      2020-12-22 16:11:30       mod: yes\nS-11     2020-12-22 13:02:00      2020-12-22 16:09:43       mod: yes\nS-12     2020-12-22 12:49:06      2020-12-22 16:10:06       mod: yes\nS-13     2020-12-22 12:49:06      2020-12-22 16:08:44       mod: yes\nS-14     2020-12-22 12:49:09      2020-12-22 16:13:45       mod: yes\nS-15     2020-12-22 12:49:03      2020-12-22 16:10:00       mod: yes\nS-BU1     2020-12-22 12:49:00      2020-12-22 16:11:40       mod: yes\n"
     ]
    }
   ],
   "source": [
    "data = cleanUp(cutOffTime,sensorConditions,all_csv_files,columns,badTimes)"
   ]
  },
  {
   "source": [
    "### Exporting Data\n",
    "Here we can export the organized data frames as csv files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './proccessedData'\n",
    "for x in data:\n",
    "    temp=data[x]\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Checking Data\n",
    "Here we scan through the data for irregularities in data recording."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "20.86 % potential error in  S-01\n",
      "  26  21  17  13  19  30  20  11\n",
      "   1   1   6   1   2   1 195   1\n",
      "\n",
      "22.86 % potential error in  S-03\n",
      "  21  12  25  27  16  18  62  84  51  20  31  11  22   9  13   0  90  15  70  59  17  19  63\n",
      "   1   2   1   2   1   7   2   1   1 171   1   3   2   1   1   1   1   1   1   1  12   4   1\n",
      "\n",
      "22.59 % potential error in  S-04\n",
      "  21  22  17  23  60  18  35  24  78  19  20  13  25  11  49\n",
      "   1   2  12   1   1  10   3   1   1   2 180   1   1   3   1\n",
      "\n",
      "22.07 % potential error in  S-05\n",
      "  26  21  16  17  23  12  18   7  19  24  25  20  15\n",
      "   1   4   1  10   2   1   7   1   2   1   1 188   1\n",
      "\n",
      "19.98 % potential error in  S-06\n",
      "  28  20  85\n",
      "   1 197   1\n",
      "\n",
      "20.89 % potential error in  S-07\n",
      "   9  16  22  14  12  34  18  24  19  30  25  20  15  17  13  11\n",
      "   1   1   2   1   1   1   1   1   9   2   1 184   2   2   1   2\n",
      "\n",
      "99.76 % potential error in  S-08\n",
      "  34  35 138 139 140  37\n",
      " 164 241   3   2   1   1\n",
      "\n",
      "0.41 % potential error in  S-09\n",
      "   9  17   3  31  20\n",
      "   1   1   1   1   1\n",
      "\n",
      "0.98 % potential error in  S-11\n",
      "  16  14  18  15  11\n",
      "   2   3   1   4   1\n",
      "\n",
      "0.17 % potential error in  S-12\n",
      "   8  12\n",
      "   1   1\n",
      "\n",
      "1.09 % potential error in  S-13\n",
      "  16  14   9  18  19  41  20  15  11\n",
      "   2   3   1   1   1   1   1   1   2\n",
      "\n",
      "1.06 % potential error in  S-14\n",
      "  16  14  17  12   9  20  15  11\n",
      "   1   3   1   2   1   1   1   3\n",
      "\n",
      "0.67 % potential error in  S-15\n",
      "  33  17   0  30  25 150  11\n",
      "   1   1   1   1   1   1   2\n",
      "\n",
      "99.83 % potential error in  S-BU1\n",
      "  61  40 241  19 240  20\n",
      "   1   2   1   2   1 575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if DataChecking:\n",
    "    directory = './dataInfo'\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    fout = open('./dataInfo/time_Frequency_Error_Log.txt','wt')\n",
    "    errors = {}\n",
    "    errorCount = {}\n",
    "    # Enter the expected interval here\n",
    "    interval = 10\n",
    "    for x in data:\n",
    "        # errors keeps track of length of each time interval error that occurs\n",
    "        errors[x] = set(())\n",
    "        # errorCount keeps track of how many times each time interval error occured\n",
    "        errorCount[x] = {}\n",
    "        # counter keeps track of the total time interval errors per sensor\n",
    "        counter = 0\n",
    "        #shows the total\n",
    "        temp = data[x]\n",
    "        for idx,i in enumerate(temp['Date_Time']):\n",
    "            try:\n",
    "                if not ((temp['Date_Time'][idx+1] - i) == pd.Timedelta(seconds=interval)):\n",
    "                    timeErr = temp['Date_Time'][idx+1] - i\n",
    "                    if str(timeErr.seconds) in errorCount[x]:\n",
    "                        errorCount[x][str(timeErr.seconds)] +=1\n",
    "                    else:\n",
    "                        errorCount[x][str(timeErr.seconds)] = 1\n",
    "\n",
    "                    errors[x].add(timeErr)\n",
    "\n",
    "\n",
    "                    counter += 1\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        print(str(round(counter/len(temp)*100,2)),'% potential error in ', x)\n",
    "        fout.write('potential error in '+ x +'\\n' + str(round(counter/len(temp)*100,2))+'%'+'\\n')\n",
    "\n",
    "        # display the different types of errors\n",
    "        lst = [i.seconds for i in errors[x]]\n",
    "        frmt = \"{:>4}\"*len(lst)\n",
    "        print(frmt.format(*lst))\n",
    "        fout.write(\"Time Errors\" + frmt.format(*lst)+ '\\n')\n",
    "\n",
    "        # display the quantity of each type of error\n",
    "        lst = [errorCount[x][str(i.seconds)] for i in errors[x]]\n",
    "        frmt = \"{:>4}\"*len(lst)\n",
    "        print(frmt.format(*lst))\n",
    "        fout.write(\"# Observed \" + frmt.format(*lst)+ '\\n')\n",
    "\n",
    "        print()\n",
    "        fout.write('\\n')\n",
    "\n",
    "\n",
    "    fout.close()"
   ]
  },
  {
   "source": [
    "Notice there are quite a few repeating errors here in our data set. We can either choose to interpolate the data inbetween or pad it with 0s. For gaps <40s i will interpolate, but for gaps >40 i will 0 pad."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S-01   ['% of values from interpolation : 34.219', '% of values from 0-padding : 0.0', '% of values not changed : 65.781']\n",
      "S-03   ['% of values from interpolation : 33.306', '% of values from 0-padding : 4.402', '% of values not changed : 62.292']\n",
      "S-04   ['% of values from interpolation : 34.967', '% of values from 0-padding : 1.578', '% of values not changed : 63.455']\n",
      "S-05   ['% of values from interpolation : 35.323', '% of values from 0-padding : 0.0', '% of values not changed : 64.677']\n",
      "S-06   ['% of values from interpolation : 33.167', '% of values from 0-padding : 0.665', '% of values not changed : 66.168']\n",
      "S-07   ['% of values from interpolation : 33.831', '% of values from 0-padding : 0.0', '% of values not changed : 66.169']\n",
      "S-08   ['% of values from interpolation : 94.186', '% of values from 0-padding : 5.814', '% of values not changed : 0.0']\n",
      "S-09   ['% of values from interpolation : 0.415', '% of values from 0-padding : 0.0', '% of values not changed : 99.585']\n",
      "S-11   ['% of values from interpolation : 0.83', '% of values from 0-padding : 6.556', '% of values not changed : 92.614']\n",
      "S-12   ['% of values from interpolation : 0.0', '% of values from 0-padding : 0.0', '% of values not changed : 100.0']\n",
      "S-13   ['% of values from interpolation : 1.334', '% of values from 0-padding : 0.0', '% of values not changed : 98.666']\n",
      "S-14   ['% of values from interpolation : 0.829', '% of values from 0-padding : 0.0', '% of values not changed : 99.171']\n",
      "S-15   ['% of values from interpolation : 0.995', '% of values from 0-padding : 1.244', '% of values not changed : 97.761']\n",
      "S-BU1   ['% of values from interpolation : 95.104', '% of values from 0-padding : 4.647', '% of values not changed : 0.249']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fout = open('./dataInfo/interpolation_Effect_Log.txt','wt')\n",
    "interpDF = {}\n",
    "\n",
    "for x in data:\n",
    "    df = data[x]\n",
    "    cutoff = 40\n",
    "    freq = '10S'\n",
    "    try:\n",
    "        interpDF[x],accuracy = fillDf(df,freq,cutOffTime,endTime,cutoff)\n",
    "        print(x,' ',accuracy)\n",
    "        fout.write(x+' '+ '\\n' + accuracy[0]+ '\\n'+ accuracy[1]+ '\\n'+ accuracy[2] +'\\n\\n')\n",
    "    except IndexError:\n",
    "        print(x,'NO DATA')\n",
    "        fout.write(x+'NO DATA'+'\\n')\n",
    "fout.close()        "
   ]
  },
  {
   "source": [
    "### Export Data\n",
    "export the newly interpolated data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './interpolatedData'\n",
    "for x in interpDF:\n",
    "    temp=interpDF[x]\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Merge the DataFrames"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10 1199\n"
     ]
    }
   ],
   "source": [
    "length = []\n",
    "for x in interpDF:\n",
    "    length.append(len(interpDF[x]))\n",
    "index = min(length)\n",
    "lowIDX,lowValue = [[i,value] for i,value in enumerate(length) if value == index][0]\n",
    "print(lowIDX,lowValue)"
   ]
  },
  {
   "source": [
    "for count,key in enumerate(list(interpDF.keys())):\n",
    "    print(count+1,key,temp[count+1])"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Date_Time  S-01  S-03  S-04  S-05  S-06  S-07  S-08  S-09  \\\n",
       "0    2020-12-22 12:49:00     0     0     0     0    18     0     0     9   \n",
       "1    2020-12-22 12:49:10     0     9     0     0    18     0     0     9   \n",
       "2    2020-12-22 12:49:20     9     9     0     0     9     0     0     9   \n",
       "3    2020-12-22 12:49:30     9    33     0     0     0     0     0     9   \n",
       "4    2020-12-22 12:49:40     0    33     0     9     0     0     0     0   \n",
       "...                  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "1194 2020-12-22 16:08:00     0     0     0     0     9     0     0     9   \n",
       "1195 2020-12-22 16:08:10     0     0     0    18     0     0     0    21   \n",
       "1196 2020-12-22 16:08:20     4     0     0    18     0     9     0     0   \n",
       "1197 2020-12-22 16:08:30    30     0     0     0     0     9     0     0   \n",
       "1198 2020-12-22 16:08:40    48     0     0     0     0     9     0     0   \n",
       "\n",
       "      S-11  S-12  S-13  S-14  S-15  S-BU1     Average       Variance  \n",
       "0        0     0     0    21     0     78    3.692308      51.443787  \n",
       "1        0     0     9     0     0     78    3.461538      31.633136  \n",
       "2        0   102    18     0     0     49   12.000000     706.153846  \n",
       "3        0    78     9     0     0     21   10.615385     457.775148  \n",
       "4        0     9     0     9     0     10    4.615385      81.159763  \n",
       "...    ...   ...   ...   ...   ...    ...         ...            ...  \n",
       "1194     0     0  1023     0     0      4   80.076923   74102.378698  \n",
       "1195     0     0  1319     9     0      0  105.153846  122835.514793  \n",
       "1196     0    33  1615     0     9      0  129.846154  183895.053254  \n",
       "1197     0    33  1911     0     9      0  153.230769  257602.792899  \n",
       "1198     0     0  3276     9     9     13  257.769231  759302.946746  \n",
       "\n",
       "[1199 rows x 17 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date_Time</th>\n      <th>S-01</th>\n      <th>S-03</th>\n      <th>S-04</th>\n      <th>S-05</th>\n      <th>S-06</th>\n      <th>S-07</th>\n      <th>S-08</th>\n      <th>S-09</th>\n      <th>S-11</th>\n      <th>S-12</th>\n      <th>S-13</th>\n      <th>S-14</th>\n      <th>S-15</th>\n      <th>S-BU1</th>\n      <th>Average</th>\n      <th>Variance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-12-22 12:49:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21</td>\n      <td>0</td>\n      <td>78</td>\n      <td>3.692308</td>\n      <td>51.443787</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-12-22 12:49:10</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>78</td>\n      <td>3.461538</td>\n      <td>31.633136</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-12-22 12:49:20</td>\n      <td>9</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>102</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>49</td>\n      <td>12.000000</td>\n      <td>706.153846</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-12-22 12:49:30</td>\n      <td>9</td>\n      <td>33</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>78</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21</td>\n      <td>10.615385</td>\n      <td>457.775148</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-12-22 12:49:40</td>\n      <td>0</td>\n      <td>33</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>10</td>\n      <td>4.615385</td>\n      <td>81.159763</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1194</th>\n      <td>2020-12-22 16:08:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1023</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>80.076923</td>\n      <td>74102.378698</td>\n    </tr>\n    <tr>\n      <th>1195</th>\n      <td>2020-12-22 16:08:10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1319</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>105.153846</td>\n      <td>122835.514793</td>\n    </tr>\n    <tr>\n      <th>1196</th>\n      <td>2020-12-22 16:08:20</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>33</td>\n      <td>1615</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>129.846154</td>\n      <td>183895.053254</td>\n    </tr>\n    <tr>\n      <th>1197</th>\n      <td>2020-12-22 16:08:30</td>\n      <td>30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>33</td>\n      <td>1911</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>153.230769</td>\n      <td>257602.792899</td>\n    </tr>\n    <tr>\n      <th>1198</th>\n      <td>2020-12-22 16:08:40</td>\n      <td>48</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3276</td>\n      <td>9</td>\n      <td>9</td>\n      <td>13</td>\n      <td>257.769231</td>\n      <td>759302.946746</td>\n    </tr>\n  </tbody>\n</table>\n<p>1199 rows × 17 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "columns = list(interpDF.keys())\n",
    "mergedData = pd.DataFrame({'Date_Time':interpDF[columns[lowIDX]]['Date_Time']})\n",
    "for idx,column in enumerate(columns):\n",
    "    mergedData[column] = interpDF[column][particle]\n",
    "Average = np.mean(mergedData[zoneList['Zone 1']+zoneList['Zone 2']+zoneList['Zone 3']],axis=1)\n",
    "Variance = np.var(mergedData[zoneList['Zone 1']+zoneList['Zone 2']+zoneList['Zone 3']],axis=1)\n",
    "mergedData['Average'] = Average\n",
    "mergedData['Variance'] = Variance\n",
    "mergedData"
   ]
  },
  {
   "source": [
    "### Increase Resolution on mergedData"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in mergedData:\n",
    "    tempFrame = mergedData.values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    hiResMergedDF = pd.DataFrame(tempList, columns = mergedData.keys())"
   ]
  },
  {
   "source": [
    "### Export Merged Frames"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './mergedData/'\n",
    "if not os.path.exists(directory):\n",
    "\n",
    "    os.makedirs(directory)\n",
    "\n",
    "location = os.path.join(directory+'mergedFrame.csv')\n",
    "hiResMergedDF.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Create csv files for each animation\n",
    "We have 3 expirements in each that we want to average across the range"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergedData = pd.read_csv('./mergedData/mergedFrame.csv',parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time = mergedData['Date_Time']\n",
    "expIndexes = {}\n",
    "for i in expTRange:\n",
    "    expIndexes[i] = []\n",
    "    for x in expTRange[i]:\n",
    "        for start,n in enumerate(time):\n",
    "           if n >= x:\n",
    "               expIndexes[i].append(start)\n",
    "               break"
   ]
  },
  {
   "source": [
    "## Determining Zones\n",
    "Here we first create 'averagedFrame's. These are dictionaries that at each 'label' (which corresponds to the name of an expirement) we have a pandas dataframe containing the results of all of the trails in an expirement summed, and then divided by the total number of trails.\n",
    "Anytime you are adjusting the Zones, everything below here must be run. The values of many of these DataFrames are mutated"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'OR7 Unblocked': [113, 165, 271],\n",
       " 'OR7 Blocked': [331, 382, 419],\n",
       " 'OR16 Unblocked': [654, 689, 725],\n",
       " 'OR16 Blocked 1': [776, 818, 852],\n",
       " 'OR16 Blocked 2': [891, 924, 966]}"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "expIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preCursorFactor is defined at the start\n",
    "averagedFrame = {}\n",
    "expirementFrame = {}\n",
    "\n",
    "for label in expIndexes:\n",
    "    runSumFrames = expIndexes[label][0]-expIndexes[label][0]\n",
    "    for idx,time in enumerate(expIndexes[label]):\n",
    "        start = expIndexes[label][idx] - preCursorFactor\n",
    "        end = expIndexes[label][idx] + expTLen[label]\n",
    "        expirementFrame[label+' Exp '+str(idx+1)] = mergedData.iloc[ start : end , 1: ].reset_index(drop = True)\n",
    "        runSumFrames += expirementFrame[label+' Exp '+str(idx+1)]\n",
    "        \n",
    "    averagedFrame[label] = runSumFrames/(idx+1)"
   ]
  },
  {
   "source": [
    "Calculating the correct Zones for each expirement"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# numAutoZones is defined at the start\n",
    "AutoZoneAssignments = {}\n",
    "for frame in averagedFrame:\n",
    "    # at this point averagedFrame should just be the averaged sum of the expirementFrame trails. Last two columns are overall average and varaince so they should be ignored.\n",
    "    avgFrm = averagedFrame[frame]\n",
    "    # outdoorSensors must have its spelling exactly match\n",
    "    columns = list(set(avgFrm.keys()[:-2])- set(outdoorSensors))\n",
    "    columns.sort()\n",
    "\n",
    "    X = {}\n",
    "    for column in columns:\n",
    "        value,index = max([(value,index) for index,value in enumerate(avgFrm[column])]) \n",
    "        X[column] = np.array([np.log(value+.01),index])\n",
    "    X = [X[i] for i in X]\n",
    "    kmeans = KMeans(n_clusters=numAutoZones,random_state=0).fit(X)\n",
    "    idx = np.argsort(kmeans.cluster_centers_.sum(axis=1))\n",
    "    lut = np.zeros_like(idx)\n",
    "    lut[idx] = np.arange(numAutoZones)\n",
    "    #lut = lut[::-1]\n",
    "    orderedZones = [[]]*numAutoZones\n",
    "    for index, zone in enumerate(lut):\n",
    "        orderedZones[index] = [index if zone == kmeans.labels_[i] else 0 for i in range(len(kmeans.labels_))]\n",
    "    AutoZoneAssignments[frame] = np.sum(orderedZones,axis=0)\n",
    "z = numAutoZones\n",
    "ZDfAuto = pd.DataFrame(AutoZoneAssignments)\n",
    "ZDfAuto = ZDfAuto.append(pd.DataFrame([[z]*len(expIndexes)]*len(outdoorSensors),columns = AutoZoneAssignments.keys()),ignore_index=True)\n",
    "AutoZoneAssignments = ZDfAuto\n",
    "if len(outdoorSensors):\n",
    "    numAutoZones += 1\n",
    "\n",
    "if not ZoneAutomation:\n",
    "    ZoneAssignments = {}\n",
    "    for frame in averagedFrame:\n",
    "        # at this point averagedFrame should just be the averaged sum of the expirementFrame trails. Last two columns are overall average and varaince so they should be ignored.\n",
    "        avgFrm = averagedFrame[frame]\n",
    "        # outdoorSensors must have its spelling exactly match\n",
    "        columns = list(set(avgFrm.keys()[:-2]))\n",
    "        columns.sort()\n",
    "        ZoneAssignments[frame] = [0]*len(columns)\n",
    "        for value,zone in enumerate(zoneList):\n",
    "            for sensor in zoneList[zone]:\n",
    "                ZoneAssignments[frame][columns.index(sensor)] = value\n",
    "    ZDf = pd.DataFrame(ZoneAssignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    OR7 Unblocked  OR7 Blocked  OR16 Unblocked  OR16 Blocked 1  OR16 Blocked 2\n",
       "0               1            1               1               2               0\n",
       "1               2            0               2               2               1\n",
       "2               1            1               1               2               0\n",
       "3               1            1               0               1               2\n",
       "4               0            1               1               2               0\n",
       "5               0            0               1               2               0\n",
       "6               2            2               2               0               1\n",
       "7               0            0               1               1               2\n",
       "8               1            1               0               1               0\n",
       "9               0            0               0               1               2\n",
       "10              0            0               0               1               2\n",
       "11              0            0               0               1               2\n",
       "12              0            0               2               2               1\n",
       "13              0            0               2               1               1\n",
       "14              3            3               3               3               3\n",
       "15              3            3               3               3               3\n",
       "16              3            3               3               3               3\n",
       "17              3            3               3               3               3"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OR7 Unblocked</th>\n      <th>OR7 Blocked</th>\n      <th>OR16 Unblocked</th>\n      <th>OR16 Blocked 1</th>\n      <th>OR16 Blocked 2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "AutoZoneAssignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './dataInfo'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "location = os.path.join(directory,'ZoneAssignments.csv')\n",
    "ZDf.to_csv(location,index=False)\n",
    "\n",
    "directory = './dataInfo'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "location = os.path.join(directory,'AutoZoneAssignments.csv')\n",
    "ZDfAuto.to_csv(location,index=False)\n",
    "\n",
    "import copy\n",
    "expirementFrameAuto = copy.deepcopy(expirementFrame)\n",
    "averagedFrameAuto = copy.deepcopy(averagedFrame)"
   ]
  },
  {
   "source": [
    "Zoning the expirement data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Zoning the Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    OR7 Unblocked  OR7 Blocked  OR16 Unblocked  OR16 Blocked 1  OR16 Blocked 2\n",
       "0               1            1               1               2               0\n",
       "1               2            0               2               2               1\n",
       "2               1            1               1               2               0\n",
       "3               1            1               0               1               2\n",
       "4               0            1               1               2               0\n",
       "5               0            0               1               2               0\n",
       "6               2            2               2               0               1\n",
       "7               0            0               1               1               2\n",
       "8               1            1               0               1               0\n",
       "9               0            0               0               1               2\n",
       "10              0            0               0               1               2\n",
       "11              0            0               0               1               2\n",
       "12              0            0               2               2               1\n",
       "13              0            0               2               1               1\n",
       "14              3            3               3               3               3\n",
       "15              3            3               3               3               3\n",
       "16              3            3               3               3               3\n",
       "17              3            3               3               3               3"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OR7 Unblocked</th>\n      <th>OR7 Blocked</th>\n      <th>OR16 Unblocked</th>\n      <th>OR16 Blocked 1</th>\n      <th>OR16 Blocked 2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "AutoZoneAssignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonedAvgFrame = {}\n",
    "for key in ZoneAssignments:\n",
    "    occourances = [list(ZoneAssignments[key]).count(x) for x in set(ZoneAssignments[key])]\n",
    "    zoneRunSum = [0]*numberOfZones\n",
    "    zonedAvgFrame[key] = averagedFrame[key]\n",
    "    for idx,column in enumerate(columns):\n",
    "        zoneRunSum[ZoneAssignments[key][idx]] += zonedAvgFrame[key][column]\n",
    "    for idx in range(numberOfZones):\n",
    "        zonedAvgFrame[key]['Zone '+str(idx+1)] = zoneRunSum[idx]/occourances[idx]\n",
    "\n",
    "# relies on columns still being the values of S-01 - last sensor\n",
    "\n",
    "# Declare an empty dictionary for storing the averaged data for each expirement at the end\n",
    "zonedExpFrame = {}\n",
    "# create a list of all of the various dict keys in expirementFrame so that we can iterate through them to get the data\n",
    "labels = list(expirementFrame.keys())\n",
    "# Take the labels list and remove the Exp # from it, so that now we have a list of keys that we can use to correctly save to create correctly corresponding keys for a dictionary that will store the averages\n",
    "keyList = [x.split(' Exp')[0] for x in labels]\n",
    "\n",
    "for index,exp in enumerate(labels):\n",
    "    # set the key variable to correspond to the exp variable\n",
    "    key = keyList[index]\n",
    "    # Create a runnning sum to keep track of the values\n",
    "    zoneRunSum = [0]*numberOfZones\n",
    "    # set the give the zoneExpFrame the same \n",
    "    zonedExpFrame[exp] = expirementFrame[exp]\n",
    "    occourances = [list(ZoneAssignments[key]).count(x) for x in set(ZoneAssignments[key])]\n",
    "    for idx,column in enumerate(columns):\n",
    "        zoneRunSum[ZoneAssignments[key][idx]] += zonedExpFrame[exp][column]\n",
    "    for idx in range(numberOfZones):\n",
    "        zonedExpFrame[exp]['Zone '+str(idx+1)] = zoneRunSum[idx]/occourances[idx]\n",
    "\n",
    "        \n",
    "zonedAvgFrameAuto = {}\n",
    "for key in AutoZoneAssignments:\n",
    "    occourances = [list(AutoZoneAssignments[key]).count(x) for x in set(AutoZoneAssignments[key])]\n",
    "    zoneRunSum = [0]*numAutoZones\n",
    "    zonedAvgFrameAuto[key] = averagedFrameAuto[key]\n",
    "    for idx,column in enumerate(columns):\n",
    "        zoneRunSum[AutoZoneAssignments[key][idx]] += zonedAvgFrameAuto[key][column]\n",
    "    for idx in range(numAutoZones):\n",
    "        zonedAvgFrameAuto[key]['Zone '+str(idx+1)] = zoneRunSum[idx]/occourances[idx]\n",
    "        \n",
    "# relies on columns still being the values of S-01 - last sensor\n",
    "\n",
    "# Declare an empty dictionary for storing the averaged data for each expirement at the end\n",
    "zonedExpFrameAuto = {}\n",
    "# create a list of all of the various dict keys in expirementFrameAuto so that we can iterate through them to get the data\n",
    "labels = list(expirementFrameAuto.keys())\n",
    "# Take the labels list and remove the Exp # from it, so that now we have a list of keys that we can use to correctly save to create correctly corresponding keys for a dictionary that will store the averages\n",
    "keyList = [x.split(' Exp ')[0] for x in labels]\n",
    "\n",
    "for index,exp in enumerate(labels):\n",
    "    # set the key variable to correspond to the exp variable\n",
    "    key = keyList[index]\n",
    "    # Create a runnning sum to keep track of the values\n",
    "    zoneRunSum = [0]*numAutoZones\n",
    "    # set the give the zoneExpFrame the same \n",
    "    zonedExpFrameAuto[exp] = expirementFrameAuto[exp]\n",
    "    occourances = [list(AutoZoneAssignments[key]).count(x) for x in set(AutoZoneAssignments[key])]\n",
    "    for idx,column in enumerate(columns):\n",
    "        zoneRunSum[AutoZoneAssignments[key][idx]] += zonedExpFrameAuto[exp][column]\n",
    "    for idx in range(numAutoZones):\n",
    "        zonedExpFrameAuto[exp]['Zone '+str(idx+1)] = zoneRunSum[idx]/occourances[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './averagedData'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in averagedFrame:\n",
    "    temp=averagedFrame[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "directory = './averagedDataAuto'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in averagedFrameAuto:\n",
    "    temp=averagedFrameAuto[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "directory = './expirementData'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in expirementFrame:\n",
    "    temp=expirementFrame[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "directory = './expirementDataAuto'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in expirementFrame:\n",
    "    temp=expirementFrame[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Increase the Resolution\n",
    "pad out the dataframes to have values for every second."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretchedDF = {}\n",
    "for i in averagedFrame:\n",
    "    tempFrame = averagedFrame[i].values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    stretchedDF[i] = pd.DataFrame(tempList, columns = expirementFrame[list(expirementFrame.keys())[0]].columns)\n",
    "\n",
    "stretchExpDf = {}\n",
    "for i in expirementFrame:\n",
    "    tempFrame = expirementFrame[i].values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    stretchExpDf[i] = pd.DataFrame(tempList, columns = expirementFrame[list(expirementFrame.keys())[0]].columns) \n",
    "stretchedDFAuto = {}\n",
    "for i in averagedFrameAuto:\n",
    "    tempFrame = averagedFrameAuto[i].values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    stretchedDFAuto[i] = pd.DataFrame(tempList, columns = expirementFrameAuto[list(expirementFrameAuto.keys())[0]].columns) \n",
    "\n",
    "stretchExpDfAuto = {}\n",
    "for i in expirementFrameAuto:\n",
    "    tempFrame = expirementFrameAuto[i].values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    stretchExpDfAuto[i] = pd.DataFrame(tempList, columns = expirementFrameAuto[list(expirementFrameAuto.keys())[0]].columns)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './stretchedAvgData'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in stretchedDF:\n",
    "    temp=stretchedDF[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "directory = './stretchedExpirementData'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in stretchExpDf:\n",
    "    temp=stretchExpDf[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "directory = './stretchedAvgDataAuto'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in stretchedDFAuto:\n",
    "    temp=stretchedDFAuto[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "directory = './stretchedExpirementDataAuto'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "for x in stretchExpDfAuto:\n",
    "    temp=stretchExpDfAuto[x]\n",
    "    location = os.path.join(directory,x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "22.60749101638794\n"
     ]
    }
   ],
   "source": [
    "end = clock.time()\n",
    "print(end-begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}