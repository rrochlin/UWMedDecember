{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### General Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import glob\n",
    "from cleanUp import cleanUp\n",
    "from fillDf import fillDf\n"
   ]
  },
  {
   "source": [
    "### Data Cleaning\n",
    "Passing the sensor data through the cleanUp function to get fix timestamps and delete null timestamps."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_files = glob.glob(\"./Data/*.txt\")\n",
    "# insert the desired start time\n",
    "cutOffTime = '12/22/2020 12:49'\n",
    "# insert the time rectifying offsets. default of for nothing {'':0}\n",
    "sensorConditions = {'BU':8,'S-':1}\n",
    "columns = [0,1,6,7,8,9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S-01     2020-12-22 12:49:10      2020-12-22 16:09:31\nS-02  NO DATA PRESENT    NO DATA PRESENT\nS-03     2020-12-22 12:49:03      2020-12-22 16:09:35\nS-04     2020-12-22 12:49:07      2020-12-22 16:09:34\nS-05     2020-12-22 12:49:01      2020-12-22 16:10:50\nS-06     2020-12-22 12:49:12      2020-12-22 16:09:25\nS-07     2020-12-22 12:49:07      2020-12-22 16:12:53\nS-08     2020-12-22 12:49:24      2020-12-22 16:57:24\nS-09     2020-12-22 12:49:00      2020-12-22 16:11:30\nS-11     2020-12-22 13:02:00      2020-12-22 16:09:43\nS-12     2020-12-22 12:49:06      2020-12-22 16:10:06\nS-13     2020-12-22 12:49:06      2020-12-22 16:08:44\nS-14     2020-12-22 12:49:09      2020-12-22 16:13:45\nS-15     2020-12-22 12:49:03      2020-12-22 16:10:00\nS-BU1     2020-12-22 12:49:00      2020-12-22 16:11:40\nS-BU2     2020-12-22 12:49:00      2020-12-22 16:10:30\n"
     ]
    }
   ],
   "source": [
    "data = cleanUp(cutOffTime,sensorConditions,all_csv_files,columns)"
   ]
  },
  {
   "source": [
    "### Exporting Data\n",
    "Here we can export the organized data frames as csv files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data:\n",
    "    temp=data[x]\n",
    "    location = os.path.join('./proccessedData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Checking Data\n",
    "Here we scan through the data for irregularities in data recording."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "208  possible errors in  S-01\n",
      "  26  21  17  13  19  30  20  11\n",
      "   1   1   6   1   2   1 195   1\n",
      "\n",
      "0  possible errors in  S-02\n",
      "\n",
      "\n",
      "\n",
      "219  possible errors in  S-03\n",
      "  21  12  25  27  16  18  62  84  51  20  31  11  22   9  13   0  90  15  70  59  17  19  63\n",
      "   1   2   1   2   1   7   2   1   1 171   1   3   2   1   1   1   1   1   1   1  12   4   1\n",
      "\n",
      "220  possible errors in  S-04\n",
      "  21  22  17  23  60  18  35  24  78  19  20  13  25  11  49\n",
      "   1   2  12   1   1  10   3   1   1   2 180   1   1   3   1\n",
      "\n",
      "220  possible errors in  S-05\n",
      "  26  21  16  17  23  12  18   7  19  24  25  20  15\n",
      "   1   4   1  10   2   1   7   1   2   1   1 188   1\n",
      "\n",
      "199  possible errors in  S-06\n",
      "  28  20  85\n",
      "   1 197   1\n",
      "\n",
      "212  possible errors in  S-07\n",
      "   9  16  22  14  12  34  18  24  19  30  25  20  15  17  13  11\n",
      "   1   1   2   1   1   1   1   1   9   2   1 184   2   2   1   2\n",
      "\n",
      "412  possible errors in  S-08\n",
      "  34  35 138 139 140  37\n",
      " 164 241   3   2   1   1\n",
      "\n",
      "5  possible errors in  S-09\n",
      "   9  17   3  31  20\n",
      "   1   1   1   1   1\n",
      "\n",
      "11  possible errors in  S-11\n",
      "  16  14  18  15  11\n",
      "   2   3   1   4   1\n",
      "\n",
      "2  possible errors in  S-12\n",
      "   8  12\n",
      "   1   1\n",
      "\n",
      "13  possible errors in  S-13\n",
      "  16  14   9  18  19  41  20  15  11\n",
      "   2   3   1   1   1   1   1   1   2\n",
      "\n",
      "13  possible errors in  S-14\n",
      "  16  14  17  12   9  20  15  11\n",
      "   1   3   1   2   1   1   1   3\n",
      "\n",
      "8  possible errors in  S-15\n",
      "  33  17   0  30  25 150  11\n",
      "   1   1   1   1   1   1   2\n",
      "\n",
      "582  possible errors in  S-BU1\n",
      "  61  40 241  19 240  20\n",
      "   1   2   1   2   1 575\n",
      "\n",
      "42  possible errors in  S-BU2\n",
      "  29  3010861\n",
      "   1  40   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "errorCount = {}\n",
    "# Enter the expected interval here\n",
    "interval = 10\n",
    "for x in data:\n",
    "    # errors keeps track of length of each time interval error that occurs\n",
    "    errors[x] = set(())\n",
    "    # errorCount keeps track of how many times each time interval error occured\n",
    "    errorCount[x] = {}\n",
    "    # counter keeps track of the total time interval errors per sensor\n",
    "    counter = 0\n",
    "    temp = data[x]\n",
    "    for idx,i in enumerate(temp['Date_Time']):\n",
    "        try:\n",
    "            if not ((temp['Date_Time'][idx+1] - i) == pd.Timedelta(seconds=interval)):\n",
    "                timeErr = temp['Date_Time'][idx+1] - i\n",
    "                if str(timeErr.seconds) in errorCount[x]:\n",
    "                    errorCount[x][str(timeErr.seconds)] +=1\n",
    "                else:\n",
    "                    errorCount[x][str(timeErr.seconds)] = 1\n",
    "\n",
    "                errors[x].add(timeErr)\n",
    "\n",
    "\n",
    "                counter += 1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(str(counter),' possible errors in ', x)\n",
    "    # display the different types of errors\n",
    "    lst = [i.seconds for i in errors[x]]\n",
    "    frmt = \"{:>4}\"*len(lst)\n",
    "    print(frmt.format(*lst))\n",
    "    # display the quantity of each type of error\n",
    "    lst = [errorCount[x][str(i.seconds)] for i in errors[x]]\n",
    "    frmt = \"{:>4}\"*len(lst)\n",
    "    print(frmt.format(*lst))\n",
    "    print()"
   ]
  },
  {
   "source": [
    "Notice there are quite a few repeating errors here in our data set. We can either choose to interpolate the data inbetween or pad it with 0s. For gaps <40s i will interpolate, but for gaps >40 i will 0 pad."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S-01   ['% of values from interpolation : 34.266', '% of values from 0-padding : 0.0', '% of values not changed : 65.734']\n",
      "S-02   NO DATA\n",
      "S-03   ['% of values from interpolation : 33.304', '% of values from 0-padding : 4.633', '% of values not changed : 62.063']\n",
      "S-04   ['% of values from interpolation : 35.052', '% of values from 0-padding : 1.661', '% of values not changed : 63.287']\n",
      "S-05   ['% of values from interpolation : 35.428', '% of values from 0-padding : 0.0', '% of values not changed : 64.572']\n",
      "S-06   ['% of values from interpolation : 33.158', '% of values from 0-padding : 0.7', '% of values not changed : 66.142']\n",
      "S-07   ['% of values from interpolation : 33.857', '% of values from 0-padding : 0.0', '% of values not changed : 66.143']\n",
      "S-08   ['% of values from interpolation : 93.881', '% of values from 0-padding : 6.119', '% of values not changed : 0.0']\n",
      "S-09   ['% of values from interpolation : 0.436', '% of values from 0-padding : 0.0', '% of values not changed : 99.564']\n",
      "S-11   ['% of values from interpolation : 0.873', '% of values from 0-padding : 1.659', '% of values not changed : 97.467']\n",
      "S-12   ['% of values from interpolation : 0.0', '% of values from 0-padding : 0.0', '% of values not changed : 100.0']\n",
      "S-13   ['% of values from interpolation : 1.405', '% of values from 0-padding : 0.0', '% of values not changed : 98.595']\n",
      "S-14   ['% of values from interpolation : 0.873', '% of values from 0-padding : 0.0', '% of values not changed : 99.127']\n",
      "S-15   ['% of values from interpolation : 1.047', '% of values from 0-padding : 1.309', '% of values not changed : 97.644']\n",
      "S-BU1   ['% of values from interpolation : 96.943', '% of values from 0-padding : 2.795', '% of values not changed : 0.262']\n",
      "S-BU2   ['% of values from interpolation : 4.983', '% of values from 0-padding : 95.017', '% of values not changed : 0.0']\n"
     ]
    }
   ],
   "source": [
    "interpDF = {}\n",
    "\n",
    "for x in data:\n",
    "    df = data[x]\n",
    "    cutoff = 40\n",
    "    freq = '10S'\n",
    "    try:\n",
    "        interpDF[x],accuracy = fillDf(df,freq,'12/22/2020 12:59:00','12/22/2020 16:10:00',cutoff)\n",
    "        print(x,' ',accuracy)\n",
    "    except IndexError:\n",
    "        print(x,'NO DATA')"
   ]
  },
  {
   "source": [
    "### Export Data\n",
    "export the newly interpolated data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./interpolatedData\\S-BU2.csv\n"
     ]
    }
   ],
   "source": [
    "for x in interpDF:\n",
    "    temp=interpDF[x]\n",
    "    location = os.path.join('./interpolatedData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "print(location)"
   ]
  },
  {
   "source": [
    "### Merge the DataFrames\n",
    "Also remove 'S-02' from the dictionary as it has no real data\n",
    "and find the least common index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1139\n"
     ]
    }
   ],
   "source": [
    "interpDF.pop('S-02',None)\n",
    "# interpDF.pop('S-BU2',None)\n",
    "# interpDF.pop('S-BU1',None)\n",
    "length = []\n",
    "for x in interpDF:\n",
    "    length.append(len(interpDF[x]))\n",
    "index = min(length)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 S-01\n1 S-03\n2 S-04\n3 S-05\n4 S-06\n5 S-07\n6 S-08\n7 S-09\n8 S-11\n9 S-12\n10 S-13\n11 S-14\n12 S-15\n13 S-BU1\n14 S-BU2\n"
     ]
    }
   ],
   "source": [
    "for count,key in enumerate(list(interpDF.keys())):\n",
    "    print(count,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged = []\n",
    "columns = list(interpDF.keys())\n",
    "columns.extend(['Average',\n",
    "'Variance',\n",
    "'Zone 1',\n",
    "'Var Z1',\n",
    "'Zone 2',\n",
    "'Var Z2',\n",
    "'Zone 3',\n",
    "'Var Z3',\n",
    "'Zone 4',\n",
    "'Var Z4'])\n",
    "\n",
    "for idx,i in enumerate(interpDF[columns[0]].values[:index]):\n",
    "    temp = []\n",
    "    temp.append(i[0])\n",
    "    for x in interpDF:\n",
    "        temp.append(interpDF[x].values[idx][1])\n",
    "    #here we add the overall average and variance columns\n",
    "    temp.append(np.average(temp[1:]))\n",
    "    temp.append(np.std(temp[1:]))\n",
    "    #here we're segregating the zones in the file giving their variance and avg\n",
    "\n",
    "    #Zone 1 the 2 sensors right on top of the nebulizer\n",
    "    lst = temp[10:12]\n",
    "    temp.append(np.average(lst))\n",
    "    temp.append(np.std(lst))\n",
    "    #Zone 2 the perimiter of the bed\n",
    "    lst = temp[7:10]\n",
    "    temp.append(np.average(lst))\n",
    "    temp.append(np.std(lst))\n",
    "    #Zone 3 the perimeter of the room\n",
    "    lst = temp[1:7]\n",
    "    lst.append(temp[14])\n",
    "    temp.append(np.average(lst))\n",
    "    temp.append(np.std(lst))\n",
    "    #Zone 4 is just the outside sensor\n",
    "    temp.append(temp[13])\n",
    "    temp.append(1)\n",
    "    dfMerged.append(temp)\n",
    "columns.insert(0,'Date_Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData = pd.DataFrame(dfMerged,columns = columns)"
   ]
  },
  {
   "source": [
    "### Export Merged Frames"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = os.path.join('./mergedData/mergedFrame.csv')\n",
    "mergedData.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Create csv files for each animation\n",
    "We have 3 expirements in each that we want to average across the range"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "expTRange = {\n",
    "    'OR7 Unblocked':\n",
    "    [pd.Timestamp('12-22-2020 13:08:00'),\n",
    "    pd.Timestamp('12-22-2020 13:16:30'),\n",
    "    pd.Timestamp('12-22-2020 13:34:15')],\n",
    "    'OR7 Blocked':\n",
    "    [pd.Timestamp('12-22-2020 13:44:30'),\n",
    "    pd.Timestamp('12-22-2020 13:53:00'),\n",
    "    pd.Timestamp('12-22-2020 13:59:00')],\n",
    "    'OR16 Unblocked':\n",
    "    [pd.Timestamp('12-22-2020 14:38:00'),\n",
    "    pd.Timestamp('12-22-2020 14:44:00'),\n",
    "    pd.Timestamp('12-22-2020 14:50:00')],\n",
    "    'OR16 Blocked 1':\n",
    "    [pd.Timestamp('12-22-2020 14:58:30'),\n",
    "    pd.Timestamp('12-22-2020 15:05:15'),\n",
    "    pd.Timestamp('12-22-2020 15:11:00')],\n",
    "    'OR16 Blocked 2':\n",
    "    [pd.Timestamp('12-22-2020 15:17:30'),\n",
    "    pd.Timestamp('12-22-2020 15:23:00'),\n",
    "    pd.Timestamp('12-22-2020 15:30:00')],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergedData = pd.read_csv('./mergedData/mergedFrame.csv',parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time = mergedData['Date_Time']\n",
    "expIndexes = {}\n",
    "for i in expTRange:\n",
    "    expIndexes[i] = []\n",
    "    for x in expTRange[i]:\n",
    "        for start,n in enumerate(time):\n",
    "           if n >= x:\n",
    "               expIndexes[i].append(start)\n",
    "               break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexRange = 24\n",
    "averagedFrame = {}\n",
    "expirementFrame = {}\n",
    "for label in expIndexes:\n",
    "    df1 = mergedData.iloc[expIndexes[label][0]-6:expIndexes[label][0]+indexRange,1:].reset_index(drop = True)\n",
    "    df2 = mergedData.iloc[expIndexes[label][1]-6:expIndexes[label][1]+indexRange,1:].reset_index(drop = True)\n",
    "    df3 = mergedData.iloc[expIndexes[label][2]-6:expIndexes[label][2]+indexRange,1:].reset_index(drop = True)\n",
    "    averagedFrame[label] = (df1 + df2 + df3)/3\n",
    "    expirementFrame[label+' Exp1'] = df1\n",
    "    expirementFrame[label+' Exp2'] = df2\n",
    "    expirementFrame[label+' Exp3'] = df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in averagedFrame:\n",
    "    temp=averagedFrame[x]\n",
    "    location = os.path.join('./averagedData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "for x in expirementFrame:\n",
    "    temp=expirementFrame[x]\n",
    "    location = os.path.join('./expirementData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Increase the Resolution\n",
    "pad out the dataframes to have values for every second."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretchedDF = {}\n",
    "for i in averagedFrame:\n",
    "    tempFrame = averagedFrame[i].values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    stretchedDF[i] = pd.DataFrame(tempList, columns = expirementFrame['OR7 Unblocked Exp1'].columns)\n",
    "\n",
    "stretchExpDf = {}\n",
    "for i in expirementFrame:\n",
    "    tempFrame = expirementFrame[i].values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    stretchExpDf[i] = pd.DataFrame(tempList, columns = expirementFrame['OR7 Unblocked Exp1'].columns)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in stretchedDF:\n",
    "    temp=stretchedDF[x]\n",
    "    location = os.path.join('./stretchedAvgData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "for x in stretchExpDf:\n",
    "    temp=stretchExpDf[x]\n",
    "    location = os.path.join('./stretchedExpirementData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}