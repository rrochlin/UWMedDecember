{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### General Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import glob\n",
    "from cleanUp import cleanUp\n",
    "from fillDf import fillDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t0 = time.time()"
   ]
  },
  {
   "source": [
    "### Data Cleaning\n",
    "Passing the sensor data through the cleanUp function to get fix timestamps and delete null timestamps."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_files = glob.glob(\"./Data/*.txt\")\n",
    "loops=len(all_csv_files)\n",
    "# insert the desired start time\n",
    "cutOffTime = '12/22/2020 12:49'\n",
    "# insert the time rectifying offsets. default of for nothing {'':0}\n",
    "sensorConditions = {'BU':8,'S-':1}\n",
    "columns = [0,1,6,7,8,9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S-01     2020-12-22 12:49:10      2020-12-22 16:09:31\nS-02  NO DATA PRESENT    NO DATA PRESENT\nS-03     2020-12-22 12:49:03      2020-12-22 16:09:35\nS-04     2020-12-22 12:49:07      2020-12-22 16:09:34\nS-05     2020-12-22 12:49:01      2020-12-22 16:10:50\nS-06     2020-12-22 12:49:12      2020-12-22 16:09:25\nS-07     2020-12-22 12:49:07      2020-12-22 16:12:53\nS-08     2020-12-22 12:49:24      2020-12-22 16:57:24\nS-09     2020-12-22 12:49:00      2020-12-22 16:11:30\nS-11     2020-12-22 13:02:00      2020-12-22 16:09:43\nS-12     2020-12-22 12:49:06      2020-12-22 16:10:06\nS-13     2020-12-22 12:49:06      2020-12-22 16:08:44\nS-14     2020-12-22 12:49:09      2020-12-22 16:13:45\nS-15     2020-12-22 12:49:03      2020-12-22 16:10:00\nS-BU1     2020-12-22 12:49:00      2020-12-22 16:11:40\nS-BU2     2020-12-22 12:49:00      2020-12-22 16:10:30\n"
     ]
    }
   ],
   "source": [
    "data = cleanUp(cutOffTime,sensorConditions,all_csv_files,columns)"
   ]
  },
  {
   "source": [
    "### Exporting Data\n",
    "Here we can export the organized data frames as csv files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data:\n",
    "    temp=data[x]\n",
    "    location = os.path.join('./proccessedData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Checking Data\n",
    "Here we scan through the data for irregularities in data recording."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "208  possible errors in  S-01\n",
      "  26  21  17  13  19  30  20  11\n",
      "   1   1   6   1   2   1 195   1\n",
      "\n",
      "0  possible errors in  S-02\n",
      "\n",
      "\n",
      "\n",
      "219  possible errors in  S-03\n",
      "  21  12  25  27  16  18  62  84  51  20  31  11  22   9  13   0  90  15  70  59  17  19  63\n",
      "   1   2   1   2   1   7   2   1   1 171   1   3   2   1   1   1   1   1   1   1  12   4   1\n",
      "\n",
      "220  possible errors in  S-04\n",
      "  21  22  17  23  60  18  35  24  78  19  20  13  25  11  49\n",
      "   1   2  12   1   1  10   3   1   1   2 180   1   1   3   1\n",
      "\n",
      "220  possible errors in  S-05\n",
      "  26  21  16  17  23  12  18   7  19  24  25  20  15\n",
      "   1   4   1  10   2   1   7   1   2   1   1 188   1\n",
      "\n",
      "199  possible errors in  S-06\n",
      "  28  20  85\n",
      "   1 197   1\n",
      "\n",
      "212  possible errors in  S-07\n",
      "   9  16  22  14  12  34  18  24  19  30  25  20  15  17  13  11\n",
      "   1   1   2   1   1   1   1   1   9   2   1 184   2   2   1   2\n",
      "\n",
      "412  possible errors in  S-08\n",
      "  34  35 138 139 140  37\n",
      " 164 241   3   2   1   1\n",
      "\n",
      "5  possible errors in  S-09\n",
      "   9  17   3  31  20\n",
      "   1   1   1   1   1\n",
      "\n",
      "11  possible errors in  S-11\n",
      "  16  14  18  15  11\n",
      "   2   3   1   4   1\n",
      "\n",
      "2  possible errors in  S-12\n",
      "   8  12\n",
      "   1   1\n",
      "\n",
      "13  possible errors in  S-13\n",
      "  16  14   9  18  19  41  20  15  11\n",
      "   2   3   1   1   1   1   1   1   2\n",
      "\n",
      "13  possible errors in  S-14\n",
      "  16  14  17  12   9  20  15  11\n",
      "   1   3   1   2   1   1   1   3\n",
      "\n",
      "8  possible errors in  S-15\n",
      "  33  17   0  30  25 150  11\n",
      "   1   1   1   1   1   1   2\n",
      "\n",
      "582  possible errors in  S-BU1\n",
      "  61  40 241  19 240  20\n",
      "   1   2   1   2   1 575\n",
      "\n",
      "42  possible errors in  S-BU2\n",
      "  29  3010861\n",
      "   1  40   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "errorCount = {}\n",
    "# Enter the expected interval here\n",
    "interval = 10\n",
    "for x in data:\n",
    "    # errors keeps track of length of each time interval error that occurs\n",
    "    errors[x] = set(())\n",
    "    # errorCount keeps track of how many times each time interval error occured\n",
    "    errorCount[x] = {}\n",
    "    # counter keeps track of the total time interval errors per sensor\n",
    "    counter = 0\n",
    "    temp = data[x]\n",
    "    for idx,i in enumerate(temp['Date_Time']):\n",
    "        try:\n",
    "            if not ((temp['Date_Time'][idx+1] - i) == pd.Timedelta(seconds=interval)):\n",
    "                timeErr = temp['Date_Time'][idx+1] - i\n",
    "                if str(timeErr.seconds) in errorCount[x]:\n",
    "                    errorCount[x][str(timeErr.seconds)] +=1\n",
    "                else:\n",
    "                    errorCount[x][str(timeErr.seconds)] = 1\n",
    "\n",
    "                errors[x].add(timeErr)\n",
    "\n",
    "\n",
    "                counter += 1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(str(counter),' possible errors in ', x)\n",
    "    # display the different types of errors\n",
    "    lst = [i.seconds for i in errors[x]]\n",
    "    frmt = \"{:>4}\"*len(lst)\n",
    "    print(frmt.format(*lst))\n",
    "    # display the quantity of each type of error\n",
    "    lst = [errorCount[x][str(i.seconds)] for i in errors[x]]\n",
    "    frmt = \"{:>4}\"*len(lst)\n",
    "    print(frmt.format(*lst))\n",
    "    print()"
   ]
  },
  {
   "source": [
    "Notice there are quite a few repeating errors here in our data set. We can either choose to interpolate the data inbetween or pad it with 0s. For gaps <40s i will interpolate, but for gaps >40 i will 0 pad."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S-01   ['% of values from interpolation : 34.266', '% of values from 0-padding : 0.0', '% of values not changed : 65.734']\n",
      "S-02   NO DATA\n",
      "S-03   ['% of values from interpolation : 33.304', '% of values from 0-padding : 4.633', '% of values not changed : 62.063']\n",
      "S-04   ['% of values from interpolation : 35.052', '% of values from 0-padding : 1.661', '% of values not changed : 63.287']\n",
      "S-05   ['% of values from interpolation : 35.428', '% of values from 0-padding : 0.0', '% of values not changed : 64.572']\n",
      "S-06   ['% of values from interpolation : 33.158', '% of values from 0-padding : 0.7', '% of values not changed : 66.142']\n",
      "S-07   ['% of values from interpolation : 33.857', '% of values from 0-padding : 0.0', '% of values not changed : 66.143']\n",
      "S-08   ['% of values from interpolation : 93.881', '% of values from 0-padding : 6.119', '% of values not changed : 0.0']\n",
      "S-09   ['% of values from interpolation : 0.436', '% of values from 0-padding : 0.0', '% of values not changed : 99.564']\n",
      "S-11   ['% of values from interpolation : 0.873', '% of values from 0-padding : 1.659', '% of values not changed : 97.467']\n",
      "S-12   ['% of values from interpolation : 0.0', '% of values from 0-padding : 0.0', '% of values not changed : 100.0']\n",
      "S-13   ['% of values from interpolation : 1.405', '% of values from 0-padding : 0.0', '% of values not changed : 98.595']\n",
      "S-14   ['% of values from interpolation : 0.873', '% of values from 0-padding : 0.0', '% of values not changed : 99.127']\n",
      "S-15   ['% of values from interpolation : 1.047', '% of values from 0-padding : 1.309', '% of values not changed : 97.644']\n",
      "S-BU1   ['% of values from interpolation : 96.943', '% of values from 0-padding : 2.795', '% of values not changed : 0.262']\n",
      "S-BU2   ['% of values from interpolation : 4.983', '% of values from 0-padding : 95.017', '% of values not changed : 0.0']\n"
     ]
    }
   ],
   "source": [
    "interpDF = {}\n",
    "\n",
    "for x in data:\n",
    "    df = data[x]\n",
    "    cutoff = 40\n",
    "    freq = '10S'\n",
    "    try:\n",
    "        interpDF[x],accuracy = fillDf(df,freq,'12/22/2020 12:59:00','12/22/2020 16:10:00',cutoff)\n",
    "        print(x,' ',accuracy)\n",
    "    except IndexError:\n",
    "        print(x,'NO DATA')"
   ]
  },
  {
   "source": [
    "### Export Data\n",
    "export the newly interpolated data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./interpolatedData\\S-BU2.csv\n"
     ]
    }
   ],
   "source": [
    "for x in interpDF:\n",
    "    temp=interpDF[x]\n",
    "    location = os.path.join('./interpolatedData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "print(location)"
   ]
  },
  {
   "source": [
    "### Merge the DataFrames\n",
    "Also remove 'S-02' from the dictionary as it has no real data\n",
    "and find the least common index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1139\n"
     ]
    }
   ],
   "source": [
    "interpDF.pop('S-02',None)\n",
    "length = []\n",
    "for x in interpDF:\n",
    "    length.append(len(interpDF[x]))\n",
    "index = min(length)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfMerged = []\n",
    "for idx,i in enumerate(interpDF['S-01'].values[:index]):\n",
    "    temp = []\n",
    "    temp.append(i[0])\n",
    "    for x in interpDF:\n",
    "        temp.append(interpDF[x].values[idx][1])\n",
    "    temp.append(np.average(temp[1:]))\n",
    "    temp.append(np.var(temp[1:]))\n",
    "    dfMerged.append(temp)\n",
    "mergedData = pd.DataFrame(dfMerged,columns = ['Date_Time','S-01', 'S-03', 'S-04', 'S-05', 'S-06', 'S-07', 'S-08', 'S-09', 'S-11', 'S-12', 'S-13', 'S-14', 'S-15', 'S-BU1', 'S-BU2','Average','Variance'])"
   ]
  },
  {
   "source": [
    "### Export Merged Frames"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = os.path.join('./mergedData/mergedFrame.csv')\n",
    "mergedData.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Time the process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "58.67095112800598\n"
     ]
    }
   ],
   "source": [
    "print(total)"
   ]
  }
 ]
}