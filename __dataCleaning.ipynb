{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### General Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "import glob\n",
    "from cleanUp import cleanUp\n",
    "from fillDf import fillDf\n"
   ]
  },
  {
   "source": [
    "### Data Cleaning\n",
    "Passing the sensor data through the cleanUp function to get fix timestamps and delete null timestamps."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csv_files = glob.glob(\"./Data/*.txt\")\n",
    "# insert the desired start time\n",
    "cutOffTime = '12/22/2020 12:49'\n",
    "# insert the time rectifying offsets. default of for nothing {'':0}\n",
    "sensorConditions = {'BU':8,'S-':1}\n",
    "columns = [0,1,6,7,8,9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S-01     2020-12-22 12:49:10      2020-12-22 16:09:31\nS-02  NO DATA PRESENT    NO DATA PRESENT\nS-03     2020-12-22 12:49:03      2020-12-22 16:09:35\nS-04     2020-12-22 12:49:07      2020-12-22 16:09:34\nS-05     2020-12-22 12:49:01      2020-12-22 16:10:50\nS-06     2020-12-22 12:49:12      2020-12-22 16:09:25\nS-07     2020-12-22 12:49:07      2020-12-22 16:12:53\nS-08     2020-12-22 12:49:24      2020-12-22 16:57:24\nS-09     2020-12-22 12:49:00      2020-12-22 16:11:30\nS-11     2020-12-22 13:02:00      2020-12-22 16:09:43\nS-12     2020-12-22 12:49:06      2020-12-22 16:10:06\nS-13     2020-12-22 12:49:06      2020-12-22 16:08:44\nS-14     2020-12-22 12:49:09      2020-12-22 16:13:45\nS-15     2020-12-22 12:49:03      2020-12-22 16:10:00\nS-BU1     2020-12-22 12:49:00      2020-12-22 16:11:40\nS-BU2     2020-12-22 12:49:00      2020-12-22 16:10:30\n"
     ]
    }
   ],
   "source": [
    "data = cleanUp(cutOffTime,sensorConditions,all_csv_files,columns)"
   ]
  },
  {
   "source": [
    "### Exporting Data\n",
    "Here we can export the organized data frames as csv files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in data:\n",
    "    temp=data[x]\n",
    "    location = os.path.join('./proccessedData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Checking Data\n",
    "Here we scan through the data for irregularities in data recording."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "208  possible errors in  S-01\n",
      "  26  21  17  13  19  30  20  11\n",
      "   1   1   6   1   2   1 195   1\n",
      "\n",
      "0  possible errors in  S-02\n",
      "\n",
      "\n",
      "\n",
      "219  possible errors in  S-03\n",
      "  21  12  25  27  16  18  62  84  51  20  31  11  22   9  13   0  90  15  70  59  17  19  63\n",
      "   1   2   1   2   1   7   2   1   1 171   1   3   2   1   1   1   1   1   1   1  12   4   1\n",
      "\n",
      "220  possible errors in  S-04\n",
      "  21  22  17  23  60  18  35  24  78  19  20  13  25  11  49\n",
      "   1   2  12   1   1  10   3   1   1   2 180   1   1   3   1\n",
      "\n",
      "220  possible errors in  S-05\n",
      "  26  21  16  17  23  12  18   7  19  24  25  20  15\n",
      "   1   4   1  10   2   1   7   1   2   1   1 188   1\n",
      "\n",
      "199  possible errors in  S-06\n",
      "  28  20  85\n",
      "   1 197   1\n",
      "\n",
      "212  possible errors in  S-07\n",
      "   9  16  22  14  12  34  18  24  19  30  25  20  15  17  13  11\n",
      "   1   1   2   1   1   1   1   1   9   2   1 184   2   2   1   2\n",
      "\n",
      "412  possible errors in  S-08\n",
      "  34  35 138 139 140  37\n",
      " 164 241   3   2   1   1\n",
      "\n",
      "5  possible errors in  S-09\n",
      "   9  17   3  31  20\n",
      "   1   1   1   1   1\n",
      "\n",
      "11  possible errors in  S-11\n",
      "  16  14  18  15  11\n",
      "   2   3   1   4   1\n",
      "\n",
      "2  possible errors in  S-12\n",
      "   8  12\n",
      "   1   1\n",
      "\n",
      "13  possible errors in  S-13\n",
      "  16  14   9  18  19  41  20  15  11\n",
      "   2   3   1   1   1   1   1   1   2\n",
      "\n",
      "13  possible errors in  S-14\n",
      "  16  14  17  12   9  20  15  11\n",
      "   1   3   1   2   1   1   1   3\n",
      "\n",
      "8  possible errors in  S-15\n",
      "  33  17   0  30  25 150  11\n",
      "   1   1   1   1   1   1   2\n",
      "\n",
      "582  possible errors in  S-BU1\n",
      "  61  40 241  19 240  20\n",
      "   1   2   1   2   1 575\n",
      "\n",
      "42  possible errors in  S-BU2\n",
      "  29  3010861\n",
      "   1  40   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "errorCount = {}\n",
    "# Enter the expected interval here\n",
    "interval = 10\n",
    "for x in data:\n",
    "    # errors keeps track of length of each time interval error that occurs\n",
    "    errors[x] = set(())\n",
    "    # errorCount keeps track of how many times each time interval error occured\n",
    "    errorCount[x] = {}\n",
    "    # counter keeps track of the total time interval errors per sensor\n",
    "    counter = 0\n",
    "    temp = data[x]\n",
    "    for idx,i in enumerate(temp['Date_Time']):\n",
    "        try:\n",
    "            if not ((temp['Date_Time'][idx+1] - i) == pd.Timedelta(seconds=interval)):\n",
    "                timeErr = temp['Date_Time'][idx+1] - i\n",
    "                if str(timeErr.seconds) in errorCount[x]:\n",
    "                    errorCount[x][str(timeErr.seconds)] +=1\n",
    "                else:\n",
    "                    errorCount[x][str(timeErr.seconds)] = 1\n",
    "\n",
    "                errors[x].add(timeErr)\n",
    "\n",
    "\n",
    "                counter += 1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(str(counter),' possible errors in ', x)\n",
    "    # display the different types of errors\n",
    "    lst = [i.seconds for i in errors[x]]\n",
    "    frmt = \"{:>4}\"*len(lst)\n",
    "    print(frmt.format(*lst))\n",
    "    # display the quantity of each type of error\n",
    "    lst = [errorCount[x][str(i.seconds)] for i in errors[x]]\n",
    "    frmt = \"{:>4}\"*len(lst)\n",
    "    print(frmt.format(*lst))\n",
    "    print()"
   ]
  },
  {
   "source": [
    "Notice there are quite a few repeating errors here in our data set. We can either choose to interpolate the data inbetween or pad it with 0s. For gaps <40s i will interpolate, but for gaps >40 i will 0 pad."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "S-01   ['% of values from interpolation : 34.266', '% of values from 0-padding : 0.0', '% of values not changed : 65.734']\n",
      "S-02   NO DATA\n",
      "S-03   ['% of values from interpolation : 33.304', '% of values from 0-padding : 4.633', '% of values not changed : 62.063']\n",
      "S-04   ['% of values from interpolation : 35.052', '% of values from 0-padding : 1.661', '% of values not changed : 63.287']\n",
      "S-05   ['% of values from interpolation : 35.428', '% of values from 0-padding : 0.0', '% of values not changed : 64.572']\n",
      "S-06   ['% of values from interpolation : 33.158', '% of values from 0-padding : 0.7', '% of values not changed : 66.142']\n",
      "S-07   ['% of values from interpolation : 33.857', '% of values from 0-padding : 0.0', '% of values not changed : 66.143']\n",
      "S-08   ['% of values from interpolation : 93.881', '% of values from 0-padding : 6.119', '% of values not changed : 0.0']\n",
      "S-09   ['% of values from interpolation : 0.436', '% of values from 0-padding : 0.0', '% of values not changed : 99.564']\n",
      "S-11   ['% of values from interpolation : 0.873', '% of values from 0-padding : 1.659', '% of values not changed : 97.467']\n",
      "S-12   ['% of values from interpolation : 0.0', '% of values from 0-padding : 0.0', '% of values not changed : 100.0']\n",
      "S-13   ['% of values from interpolation : 1.405', '% of values from 0-padding : 0.0', '% of values not changed : 98.595']\n",
      "S-14   ['% of values from interpolation : 0.873', '% of values from 0-padding : 0.0', '% of values not changed : 99.127']\n",
      "S-15   ['% of values from interpolation : 1.047', '% of values from 0-padding : 1.309', '% of values not changed : 97.644']\n",
      "S-BU1   ['% of values from interpolation : 96.943', '% of values from 0-padding : 2.795', '% of values not changed : 0.262']\n",
      "S-BU2   ['% of values from interpolation : 4.983', '% of values from 0-padding : 95.017', '% of values not changed : 0.0']\n"
     ]
    }
   ],
   "source": [
    "interpDF = {}\n",
    "\n",
    "for x in data:\n",
    "    df = data[x]\n",
    "    cutoff = 40\n",
    "    freq = '10S'\n",
    "    try:\n",
    "        interpDF[x],accuracy = fillDf(df,freq,'12/22/2020 12:59:00','12/22/2020 16:10:00',cutoff)\n",
    "        print(x,' ',accuracy)\n",
    "    except IndexError:\n",
    "        print(x,'NO DATA')"
   ]
  },
  {
   "source": [
    "### Export Data\n",
    "export the newly interpolated data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "./interpolatedData\\S-BU2.csv\n"
     ]
    }
   ],
   "source": [
    "for x in interpDF:\n",
    "    temp=interpDF[x]\n",
    "    location = os.path.join('./interpolatedData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "print(location)"
   ]
  },
  {
   "source": [
    "### Merge the DataFrames\n",
    "Also remove 'S-02' from the dictionary as it has no real data\n",
    "and find the least common index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1139\n"
     ]
    }
   ],
   "source": [
    "interpDF.pop('S-02',None)\n",
    "# interpDF.pop('S-BU2',None)\n",
    "# interpDF.pop('S-BU1',None)\n",
    "length = []\n",
    "for x in interpDF:\n",
    "    length.append(len(interpDF[x]))\n",
    "index = min(length)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 S-01 48\n2 S-03 0\n3 S-04 0\n4 S-05 0\n5 S-06 0\n6 S-07 9\n7 S-08 0\n8 S-09 0\n9 S-11 0\n10 S-12 0\n11 S-13 3276\n12 S-14 9\n13 S-15 9\n14 S-BU1 13\n15 S-BU2 177\n"
     ]
    }
   ],
   "source": [
    "for count,key in enumerate(list(interpDF.keys())):\n",
    "    print(count+1,key,temp[count+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-50-2ec92d472fda>, line 45)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-50-2ec92d472fda>\"\u001b[1;36m, line \u001b[1;32m45\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "dfMerged = []\n",
    "columns = list(interpDF.keys())\n",
    "columns.extend(['Average',\n",
    "'Variance',\n",
    "'Zone 1',\n",
    "'Var Z1',\n",
    "'Zone 2',\n",
    "'Var Z2',\n",
    "'Zone 3',\n",
    "'Var Z3',\n",
    "'Zone 4',\n",
    "'Var Z4'])\n",
    "\n",
    "for idx,i in enumerate(interpDF[columns[0]].values[:index]):\n",
    "    temp = []\n",
    "    temp.append(i[0])\n",
    "    for x in interpDF:\n",
    "        temp.append(interpDF[x].values[idx][1])\n",
    "    #So we now have a list with the timestamp and then sensors\n",
    "    \n",
    "    #here we add the overall average and variance columns\n",
    "    temp.append(np.average(temp[1:]))\n",
    "    temp.append(np.std(temp[1:]))\n",
    "\n",
    "    #here we're segregating the zones in the file giving their variance and avg\n",
    "\n",
    "    #Zone 1 the 2 sensors right on top of the nebulizer\n",
    "    lst = temp[11:13]\n",
    "    temp.append(np.average(lst))\n",
    "    temp.append(np.std(lst))\n",
    "    #Zone 2 the perimiter of the bed\n",
    "    lst = temp[8:11]\n",
    "    temp.append(np.average(lst))\n",
    "    temp.append(np.std(lst))\n",
    "    #Zone 3 the perimeter of the room\n",
    "    lst = temp[1:8]\n",
    "    lst.append(temp[15])\n",
    "    temp.append(np.average(lst))\n",
    "    temp.append(np.std(lst))\n",
    "    #Zone 4 is just the outside sensor\n",
    "    temp.append(temp[14])\n",
    "    temp.append(1)\n",
    "    dfMerged.append(temp)\n",
    "columns.insert(0,'Date_Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3276, 9]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "temp[11:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedData = pd.DataFrame(dfMerged,columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Date_Time  S-01  S-03  S-04  S-05  S-06  S-07  S-08  S-09  \\\n",
       "0    2020-12-22 12:59:00     9     0     9    27     0     9     0     0   \n",
       "1    2020-12-22 12:59:10     4     0     0    27     4     9     0     9   \n",
       "2    2020-12-22 12:59:20     9     0     0    18     9     9     0     9   \n",
       "3    2020-12-22 12:59:30     9    18     9     9     0     9     0     0   \n",
       "4    2020-12-22 12:59:40     9    18    27    18     0     9     0     0   \n",
       "...                  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "1134 2020-12-22 16:08:00     0     0     0     0     9     0     0     9   \n",
       "1135 2020-12-22 16:08:10     0     0     0    18     0     0     0    21   \n",
       "1136 2020-12-22 16:08:20     4     0     0    18     0     9     0     0   \n",
       "1137 2020-12-22 16:08:30    30     0     0     0     0     9     0     0   \n",
       "1138 2020-12-22 16:08:40    48     0     0     0     0     9     0     0   \n",
       "\n",
       "      S-11  ...     Average    Variance  Zone 1  Var Z1  Zone 2     Var Z2  \\\n",
       "0        0  ...    6.200000    7.899367     4.5     4.5     7.0   9.899495   \n",
       "1        0  ...    4.933333    6.749691     4.5     4.5     6.0   4.242641   \n",
       "2        0  ...    7.800000   11.609264    24.0    24.0     6.0   4.242641   \n",
       "3        0  ...    7.400000    8.206705    13.5    13.5     7.0   9.899495   \n",
       "4        0  ...    9.866667   10.487294    13.5    13.5    10.0  14.142136   \n",
       "...    ...  ...         ...         ...     ...     ...     ...        ...   \n",
       "1134     0  ...   81.466667  247.295842   511.5   511.5     3.0   4.242641   \n",
       "1135     0  ...  103.933333  317.749797   664.0   655.0     7.0   9.899495   \n",
       "1136     0  ...  125.000000  388.137379   807.5   807.5    11.0  15.556349   \n",
       "1137     0  ...  144.933333  459.082709   955.5   955.5    11.0  15.556349   \n",
       "1138     0  ...  236.066667  787.809817  1642.5  1633.5     0.0   0.000000   \n",
       "\n",
       "      Zone 3     Var Z3  Zone 4  Var Z4  \n",
       "0      6.750   8.714213       0       1  \n",
       "1      5.875   8.476991       0       1  \n",
       "2      6.375   5.893588       0       1  \n",
       "3      7.875   5.395310       0       1  \n",
       "4     10.875   8.866193       4       1  \n",
       "...      ...        ...     ...     ...  \n",
       "1134  23.250  58.186661       4       1  \n",
       "1135  26.250  62.924061       0       1  \n",
       "1136  27.250  60.672790       0       1  \n",
       "1137  27.625  59.160666       0       1  \n",
       "1138  29.250  57.954184      13       1  \n",
       "\n",
       "[1139 rows x 26 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date_Time</th>\n      <th>S-01</th>\n      <th>S-03</th>\n      <th>S-04</th>\n      <th>S-05</th>\n      <th>S-06</th>\n      <th>S-07</th>\n      <th>S-08</th>\n      <th>S-09</th>\n      <th>S-11</th>\n      <th>...</th>\n      <th>Average</th>\n      <th>Variance</th>\n      <th>Zone 1</th>\n      <th>Var Z1</th>\n      <th>Zone 2</th>\n      <th>Var Z2</th>\n      <th>Zone 3</th>\n      <th>Var Z3</th>\n      <th>Zone 4</th>\n      <th>Var Z4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-12-22 12:59:00</td>\n      <td>9</td>\n      <td>0</td>\n      <td>9</td>\n      <td>27</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>6.200000</td>\n      <td>7.899367</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>7.0</td>\n      <td>9.899495</td>\n      <td>6.750</td>\n      <td>8.714213</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-12-22 12:59:10</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>27</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4.933333</td>\n      <td>6.749691</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>6.0</td>\n      <td>4.242641</td>\n      <td>5.875</td>\n      <td>8.476991</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-12-22 12:59:20</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>9</td>\n      <td>9</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7.800000</td>\n      <td>11.609264</td>\n      <td>24.0</td>\n      <td>24.0</td>\n      <td>6.0</td>\n      <td>4.242641</td>\n      <td>6.375</td>\n      <td>5.893588</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-12-22 12:59:30</td>\n      <td>9</td>\n      <td>18</td>\n      <td>9</td>\n      <td>9</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>7.400000</td>\n      <td>8.206705</td>\n      <td>13.5</td>\n      <td>13.5</td>\n      <td>7.0</td>\n      <td>9.899495</td>\n      <td>7.875</td>\n      <td>5.395310</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-12-22 12:59:40</td>\n      <td>9</td>\n      <td>18</td>\n      <td>27</td>\n      <td>18</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>9.866667</td>\n      <td>10.487294</td>\n      <td>13.5</td>\n      <td>13.5</td>\n      <td>10.0</td>\n      <td>14.142136</td>\n      <td>10.875</td>\n      <td>8.866193</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1134</th>\n      <td>2020-12-22 16:08:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>...</td>\n      <td>81.466667</td>\n      <td>247.295842</td>\n      <td>511.5</td>\n      <td>511.5</td>\n      <td>3.0</td>\n      <td>4.242641</td>\n      <td>23.250</td>\n      <td>58.186661</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1135</th>\n      <td>2020-12-22 16:08:10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21</td>\n      <td>0</td>\n      <td>...</td>\n      <td>103.933333</td>\n      <td>317.749797</td>\n      <td>664.0</td>\n      <td>655.0</td>\n      <td>7.0</td>\n      <td>9.899495</td>\n      <td>26.250</td>\n      <td>62.924061</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1136</th>\n      <td>2020-12-22 16:08:20</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>18</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>125.000000</td>\n      <td>388.137379</td>\n      <td>807.5</td>\n      <td>807.5</td>\n      <td>11.0</td>\n      <td>15.556349</td>\n      <td>27.250</td>\n      <td>60.672790</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1137</th>\n      <td>2020-12-22 16:08:30</td>\n      <td>30</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>144.933333</td>\n      <td>459.082709</td>\n      <td>955.5</td>\n      <td>955.5</td>\n      <td>11.0</td>\n      <td>15.556349</td>\n      <td>27.625</td>\n      <td>59.160666</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1138</th>\n      <td>2020-12-22 16:08:40</td>\n      <td>48</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>236.066667</td>\n      <td>787.809817</td>\n      <td>1642.5</td>\n      <td>1633.5</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>29.250</td>\n      <td>57.954184</td>\n      <td>13</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1139 rows Ã— 26 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "mergedData"
   ]
  },
  {
   "source": [
    "### Export Merged Frames"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = os.path.join('./mergedData/mergedFrame.csv')\n",
    "mergedData.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Create csv files for each animation\n",
    "We have 3 expirements in each that we want to average across the range"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "expTRange = {\n",
    "    'OR7 Unblocked':\n",
    "    [pd.Timestamp('12-22-2020 13:08:00'),\n",
    "    pd.Timestamp('12-22-2020 13:16:30'),\n",
    "    pd.Timestamp('12-22-2020 13:34:15')],\n",
    "    'OR7 Blocked':\n",
    "    [pd.Timestamp('12-22-2020 13:44:30'),\n",
    "    pd.Timestamp('12-22-2020 13:53:00'),\n",
    "    pd.Timestamp('12-22-2020 13:59:00')],\n",
    "    'OR16 Unblocked':\n",
    "    [pd.Timestamp('12-22-2020 14:38:00'),\n",
    "    pd.Timestamp('12-22-2020 14:44:00'),\n",
    "    pd.Timestamp('12-22-2020 14:50:00')],\n",
    "    'OR16 Blocked 1':\n",
    "    [pd.Timestamp('12-22-2020 14:58:30'),\n",
    "    pd.Timestamp('12-22-2020 15:05:15'),\n",
    "    pd.Timestamp('12-22-2020 15:11:00')],\n",
    "    'OR16 Blocked 2':\n",
    "    [pd.Timestamp('12-22-2020 15:17:30'),\n",
    "    pd.Timestamp('12-22-2020 15:23:00'),\n",
    "    pd.Timestamp('12-22-2020 15:30:00')],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mergedData = pd.read_csv('./mergedData/mergedFrame.csv',parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time = mergedData['Date_Time']\n",
    "expIndexes = {}\n",
    "for i in expTRange:\n",
    "    expIndexes[i] = []\n",
    "    for x in expTRange[i]:\n",
    "        for start,n in enumerate(time):\n",
    "           if n >= x:\n",
    "               expIndexes[i].append(start)\n",
    "               break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexRange = 24\n",
    "averagedFrame = {}\n",
    "expirementFrame = {}\n",
    "for label in expIndexes:\n",
    "    df1 = mergedData.iloc[expIndexes[label][0]-6:expIndexes[label][0]+indexRange,1:].reset_index(drop = True)\n",
    "    df2 = mergedData.iloc[expIndexes[label][1]-6:expIndexes[label][1]+indexRange,1:].reset_index(drop = True)\n",
    "    df3 = mergedData.iloc[expIndexes[label][2]-6:expIndexes[label][2]+indexRange,1:].reset_index(drop = True)\n",
    "    averagedFrame[label] = (df1 + df2 + df3)/3\n",
    "    expirementFrame[label+' Exp1'] = df1\n",
    "    expirementFrame[label+' Exp2'] = df2\n",
    "    expirementFrame[label+' Exp3'] = df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in averagedFrame:\n",
    "    temp=averagedFrame[x]\n",
    "    location = os.path.join('./averagedData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "for x in expirementFrame:\n",
    "    temp=expirementFrame[x]\n",
    "    location = os.path.join('./expirementData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "source": [
    "### Increase the Resolution\n",
    "pad out the dataframes to have values for every second."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stretchedDF = {}\n",
    "for i in averagedFrame:\n",
    "    tempFrame = averagedFrame[i].values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    stretchedDF[i] = pd.DataFrame(tempList, columns = expirementFrame['OR7 Unblocked Exp1'].columns)\n",
    "\n",
    "stretchExpDf = {}\n",
    "for i in expirementFrame:\n",
    "    tempFrame = expirementFrame[i].values\n",
    "    tempList = []\n",
    "    for idx,x in enumerate(tempFrame):\n",
    "        try:\n",
    "            increment = (tempFrame[idx+1] - x)/10\n",
    "            for count in range(10):\n",
    "                tempList.append(x+increment*count)\n",
    "        except IndexError:\n",
    "            tempList.append(x)\n",
    "            continue\n",
    "    stretchExpDf[i] = pd.DataFrame(tempList, columns = expirementFrame['OR7 Unblocked Exp1'].columns)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in stretchedDF:\n",
    "    temp=stretchedDF[x]\n",
    "    location = os.path.join('./stretchedAvgData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)\n",
    "for x in stretchExpDf:\n",
    "    temp=stretchExpDf[x]\n",
    "    location = os.path.join('./stretchedExpirementData',x+'.csv')\n",
    "    temp.to_csv(location,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}